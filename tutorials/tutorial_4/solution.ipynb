{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Torch and Tensorflow on the GPU vs NumPy on the CPU\n",
    "\n",
    "### Exercise 1: Matrix Multiplication\n",
    "\n",
    "In this exercise, we will compare the computation speed of matrix multiplication using `numpy`, `torch`, and `tensorflow`. We will use the `numpy`, `torch`, and `tensorflow` libraries to perform matrix multiplication and compare the computation speed of the three libraries.\n",
    "\n",
    "**Questions**\n",
    "1. import the necessary libraries (numpy, torch, tensorflow)\n",
    "2. create two random matrices of size 1000x1000\n",
    "3. perform matrix multiplication using numpy, torch, and tensorflow and compare the computation speed of the three libraries using timeit function\n",
    "4. conclude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if gpu is available for both tensorflow and pytorch\n",
    "# and import the necessary libraries\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "from torch import matmul as torch_matmul\n",
    "from tensorflow import matmul as tf_matmul\n",
    "from numpy import matmul as np_matmul\n",
    "\n",
    "\n",
    "# number of elements in the matrix\n",
    "n = 1000\n",
    "\n",
    "tf_is_gpu_available = tf.test.is_gpu_available()\n",
    "torch_is_gpu_available = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"GPU available for tensorflow: \", tf_is_gpu_available)\n",
    "print(\"GPU available for pytorch: \", torch_is_gpu_available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a random matrix for tensorflow and place it on the gpu\n",
    "tf.random.set_seed(0)\n",
    "A_tf = tf.random.normal((n, n))\n",
    "B_tf = tf.random.normal((n, n))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "tf_matmul(A_tf, B_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(A_tf)\n",
    "del(B_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a random matrix for pytorch and place it on the gpu\n",
    "torch.manual_seed(0)\n",
    "A_torch = torch.randn(n, n).to(device='cuda')\n",
    "B_torch = torch.randn(n, n).to(device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "torch_matmul(A_torch, B_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(A_torch)\n",
    "del(B_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a random matrix for numpy\n",
    "np.random.seed(0)\n",
    "A_np = np.random.randn(n, n).astype(np.float32)\n",
    "B_np = np.random.randn(n, n).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "np_matmul(A_np, B_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entropy \n",
    "\n",
    "### Exercise 2: \n",
    "\n",
    "In this exercise, we will compute the entropy of a binary sequence and compress the sequence using different models. We will compare the entropy of the original and compressed sequences to understand the effectiveness of the compression models.\n",
    "\n",
    "**Questions**\n",
    "1. Create a sequence of 10000 binaries with a specific bernoulli distribution (p=0.99)\n",
    "2. compute the entropy of this distribution using Shannon's entropy formula\n",
    "3. define some models to compress the sequence (encode the sequences of 1)\n",
    "4. pick the best model and compress the sequence (don't forget to include model complexity)\n",
    "4. compute the empirical entropy of the compressed sequence\n",
    "5. compare the entropy of the original and compressed sequences \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# number of elements in the matrix\n",
    "n = 10000\n",
    "\n",
    "# Create a sequence of n binaries with a specific bernoulli distribution (p=0.99)\n",
    "np.random.seed(42)  # For reproducibility\n",
    "sequence = np.random.binomial(n=1, p=0.99, size=n)\n",
    "\n",
    "# Compute the entropy of this distribution using Shannon's entropy formula\n",
    "def shannon_entropy(p):\n",
    "    if p == 0 or p == 1:\n",
    "        return 0\n",
    "    return -p * math.log2(p) - (1-p) * math.log2(1-p)\n",
    "\n",
    "theoretical_entropy = shannon_entropy(0.99)\n",
    "\n",
    "print(f\"Theoretical entropy       : {theoretical_entropy:.6f}\")\n",
    "print(f\"Theoretical average length: {round(theoretical_entropy * n)} bits\")\n",
    "\n",
    "\n",
    "# Consider the following encoding scheme:\n",
    "# if I got a 0, I will encode it as 0\n",
    "# if I got a 1, I will encode it as 1 followed by the number p of consecutive 1s until the next 0\n",
    "# we will tests 1 to k=10 as length of p and pick the best one\n",
    "def compress(sequence, p):\n",
    "    encoded_sequence = []\n",
    "    encoded_sequence_length = 0\n",
    "    i = 0\n",
    "    while i < len(sequence):\n",
    "        if sequence[i] == 0:\n",
    "            encoded_sequence.append(0)\n",
    "            encoded_sequence_length += 1\n",
    "            i += 1\n",
    "        else:\n",
    "            encoded_sequence.append(1)\n",
    "            count = 0\n",
    "            while i < len(sequence) and sequence[i] == 1 and count < p:\n",
    "                count += 1\n",
    "                i += 1\n",
    "            encoded_sequence_length += 1 + np.log2(p)\n",
    "            encoded_sequence.append(count)\n",
    "    return encoded_sequence, encoded_sequence_length\n",
    "\n",
    "\n",
    "k = 20\n",
    "compressions = []\n",
    "for l in range(1, k+1):\n",
    "    # model complexity\n",
    "    model_complexity = 1 + l\n",
    "\n",
    "    # Compute the empirical entropy of the encoded sequence\n",
    "    p = 2**l\n",
    "    encoded_sequence, encoded_sequence_length = compress(sequence, p)\n",
    "    compressions.append((l, model_complexity + encoded_sequence_length))\n",
    "\n",
    "\n",
    "    \n",
    "# plot compression as a function of l\n",
    "plt.plot([c[0] for c in compressions], [c[1] for c in compressions])\n",
    "plt.xlabel(\"l: model complexity\")\n",
    "plt.ylabel(\"Compression\")\n",
    "plt.title(\"Compression as a function of l\")\n",
    "plt.show()\n",
    "\n",
    "# print best compression\n",
    "best_compression = min(compressions, key=lambda x: x[1])\n",
    "print(f\"Best compression: {best_compression[1]} bits with l={best_compression[0]}\")\n",
    "print(f\"Empirical entropy: {best_compression[1] / n:.6f}\")\n",
    "print(f\"Theoretical entropy: {theoretical_entropy:.6f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation Cross-Entropy Convergence\n",
    "\n",
    "### Exercise 3:\n",
    "\n",
    "In this exercise, we will test empirically the convergence of the validation cross-entropy loss to the true cross-entropy loss when the number of samples is large. \n",
    "\n",
    "Consider the following model: \\\n",
    "for each point i represented by $x_i \\in R^2$, we define $y_i = min(|x_i - \\alpha_1|_{\\infty}, |x_i - \\alpha_2|_{\\infty}) - 1$ with $\\alpha_1 = (0, 2)$ and $\\alpha_2 = (0, -2)$ and  $\\epsilon_i \\sim \\mathcal{Ber}(0.3)$. \\\n",
    "We then define two regions $R_1 = \\{x \\in R^2, y \\leq 0\\}$ and $R_2 = \\{x \\in R^2, y > 0\\}$.\\\n",
    "And a border zone $B = \\{x \\in R^2, y = 0\\}$.\\\n",
    "Assume we have two classes for the points $x_i$: $c_0$ and $c_1$. \n",
    "- if $x_i \\in R_1$, $d(x_i,B) \\leq 0.2$ and $\\epsilon_i = 0$, then $c_i = c_0$\n",
    "- if $x_i \\in R_1$, $d(x_i,B) \\leq 0.2$ and $\\epsilon_i = 1$, then $c_i = c_1$\n",
    "- if $x_i \\in R_1$, $d(x_i,B)>0.2$, then $c_i = c_0$\n",
    "- if $x_i \\in R_2$, $d(x_i,B) \\leq 0.2$ and $\\epsilon_i = 0$, then $c_i = c_1$\n",
    "- if $x_i \\in R_2$, $d(x_i,B) \\leq 0.2$ and $\\epsilon_i = 1$, then $c_i = c_0$\n",
    "- if $x_i \\in R_2$, $d(x_i,B)>0.2$, then $c_i = c_1$\n",
    "\n",
    "where $d(x,B) = min_{b \\in B} |x-b|_{\\infty}$.\n",
    "\n",
    "To be able to compute the true cross-entropy loss, we assume that $x_i \\sim \\mathcal{U}([-3,3]^2)$.\n",
    "\n",
    "\n",
    "**Part 1 - Questions: data vizualisation**\n",
    "1. Generate 1000 points $x_i$ and compute the corresponding $y_i$.\n",
    "2. Plot the points $x_i$ in the plane and color them according to their class.\n",
    "3. compute the theoretical cross-entropy loss of the model.\n",
    "4. compute the empirical cross-entropy loss of the model using the generated points and compare it to the theoretical one.\n",
    "\n",
    "Next, we approximate the true cross-entropy loss using the grid (100x100) of points $x_i$ in $[-3,3]^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# sample size\n",
    "n = 10000\n",
    "\n",
    "# set the seed\n",
    "np.random.seed(0)\n",
    "\n",
    "# define clusters centers\n",
    "alpha_1 = np.array([0, 2])\n",
    "alpha_2 = np.array([0, -2])\n",
    "\n",
    "# generate the data\n",
    "epsilon = np.random.binomial(n=1, p=0.3, size=n)\n",
    "x = 7 * np.random.rand(n, 2) - 3.5\n",
    "y = (np.concat((np.abs(x - alpha_1).max(axis=-1)[:, None], np.abs(x - alpha_2).max(axis=-1)[:, None]), axis=-1)).min(axis=-1) - 1\n",
    "regions = (y > 0).astype(int) + 1\n",
    "\n",
    "# buffer zone \n",
    "buffer_y_inner = (np.concat((np.abs(x - alpha_1).max(axis=-1)[:, None], np.abs(x - alpha_2).max(axis=-1)[:, None]), axis=-1)).min(axis=-1) - 0.8\n",
    "buffer_y_outer = (np.concat((np.abs(x - alpha_1).max(axis=-1)[:, None], np.abs(x - alpha_2).max(axis=-1)[:, None]), axis=-1)).min(axis=-1) - 1.2\n",
    "buffer_inner = 1 * (buffer_y_inner >= 0)\n",
    "buffer_outer = 1 * (buffer_y_outer <= 0)\n",
    "buffer_zone = buffer_inner * buffer_outer\n",
    "\n",
    "# compute classes\n",
    "classes = []\n",
    "for region, is_in_buffer_zone, flip_error in zip(regions.tolist(), buffer_zone.tolist(), epsilon.tolist()):\n",
    "    if is_in_buffer_zone:\n",
    "        if region == 1:\n",
    "            if flip_error:\n",
    "                classes.append(1)\n",
    "            else:\n",
    "                classes.append(0)\n",
    "        else:\n",
    "            if flip_error:\n",
    "                classes.append(0)\n",
    "            else:\n",
    "                classes.append(1)\n",
    "    else:\n",
    "        classes.append(region-1)\n",
    "classes = np.array(classes)\n",
    "\n",
    "# plot the data with small sizes for scattered points\n",
    "plt.scatter(x[classes == 0, 0], x[classes == 0, 1], color='purple', label='Class 0', s=1)\n",
    "plt.scatter(x[classes == 1, 0], x[classes == 1, 1], color='orange', label='Class 1', s=1)\n",
    "plt.legend()\n",
    "plt.xlabel(\"x1\")\n",
    "plt.ylabel(\"x2\")\n",
    "\n",
    "# draw the buffer zone\n",
    "# inner boundery square 1 vertices\n",
    "inner_boundery_square_1_v1 = [-.8, -1.2]\n",
    "inner_boundery_square_1_v2 = [.8, -1.2]\n",
    "inner_boundery_square_1_v3 = [.8, -2.8]\n",
    "inner_boundery_square_1_v4 = [-.8, -2.8]\n",
    "# draw inner boundery square 1\n",
    "plt.plot([inner_boundery_square_1_v1[0], inner_boundery_square_1_v2[0]], [inner_boundery_square_1_v1[1], inner_boundery_square_1_v2[1]], color='red')\n",
    "plt.plot([inner_boundery_square_1_v2[0], inner_boundery_square_1_v3[0]], [inner_boundery_square_1_v2[1], inner_boundery_square_1_v3[1]], color='red')\n",
    "plt.plot([inner_boundery_square_1_v3[0], inner_boundery_square_1_v4[0]], [inner_boundery_square_1_v3[1], inner_boundery_square_1_v4[1]], color='red')\n",
    "plt.plot([inner_boundery_square_1_v4[0], inner_boundery_square_1_v1[0]], [inner_boundery_square_1_v4[1], inner_boundery_square_1_v1[1]], color='red')\n",
    "# inner boundery square 2 vertices\n",
    "inner_boundery_square_2_v1 = [-.8, 1.2]\n",
    "inner_boundery_square_2_v2 = [.8, 1.2]\n",
    "inner_boundery_square_2_v3 = [.8, 2.8]\n",
    "inner_boundery_square_2_v4 = [-.8, 2.8]\n",
    "# draw inner boundery square 2\n",
    "plt.plot([inner_boundery_square_2_v1[0], inner_boundery_square_2_v2[0]], [inner_boundery_square_2_v1[1], inner_boundery_square_2_v2[1]], color='red')\n",
    "plt.plot([inner_boundery_square_2_v2[0], inner_boundery_square_2_v3[0]], [inner_boundery_square_2_v2[1], inner_boundery_square_2_v3[1]], color='red')\n",
    "plt.plot([inner_boundery_square_2_v3[0], inner_boundery_square_2_v4[0]], [inner_boundery_square_2_v3[1], inner_boundery_square_2_v4[1]], color='red')\n",
    "plt.plot([inner_boundery_square_2_v4[0], inner_boundery_square_2_v1[0]], [inner_boundery_square_2_v4[1], inner_boundery_square_2_v1[1]], color='red')\n",
    "# outer boundery square 1 vertices\n",
    "outer_boundery_square_1_v1 = [-1.2, -.8]\n",
    "outer_boundery_square_1_v2 = [1.2, -.8]\n",
    "outer_boundery_square_1_v3 = [1.2, -3.2]\n",
    "outer_boundery_square_1_v4 = [-1.2, -3.2]\n",
    "# draw outer boundery square 1\n",
    "plt.plot([outer_boundery_square_1_v1[0], outer_boundery_square_1_v2[0]], [outer_boundery_square_1_v1[1], outer_boundery_square_1_v2[1]], color='red')\n",
    "plt.plot([outer_boundery_square_1_v2[0], outer_boundery_square_1_v3[0]], [outer_boundery_square_1_v2[1], outer_boundery_square_1_v3[1]], color='red')\n",
    "plt.plot([outer_boundery_square_1_v3[0], outer_boundery_square_1_v4[0]], [outer_boundery_square_1_v3[1], outer_boundery_square_1_v4[1]], color='red')\n",
    "plt.plot([outer_boundery_square_1_v4[0], outer_boundery_square_1_v1[0]], [outer_boundery_square_1_v4[1], outer_boundery_square_1_v1[1]], color='red')\n",
    "# outer boundery square 2 vertices\n",
    "outer_boundery_square_2_v1 = [-1.2, .8]\n",
    "outer_boundery_square_2_v2 = [1.2, .8]  \n",
    "outer_boundery_square_2_v3 = [1.2, 3.2]\n",
    "outer_boundery_square_2_v4 = [-1.2, 3.2]\n",
    "# draw outer boundery square 2\n",
    "plt.plot([outer_boundery_square_2_v1[0], outer_boundery_square_2_v2[0]], [outer_boundery_square_2_v1[1], outer_boundery_square_2_v2[1]], color='red')\n",
    "plt.plot([outer_boundery_square_2_v2[0], outer_boundery_square_2_v3[0]], [outer_boundery_square_2_v2[1], outer_boundery_square_2_v3[1]], color='red')\n",
    "plt.plot([outer_boundery_square_2_v3[0], outer_boundery_square_2_v4[0]], [outer_boundery_square_2_v3[1], outer_boundery_square_2_v4[1]], color='red')\n",
    "plt.plot([outer_boundery_square_2_v4[0], outer_boundery_square_2_v1[0]], [outer_boundery_square_2_v4[1], outer_boundery_square_2_v1[1]], color='red')\n",
    "\n",
    "\n",
    "# vertices of boundery square 1\n",
    "boundery_square_1_v1 = [-1, -3]\n",
    "boundery_square_1_v2 = [1, -3]\n",
    "boundery_square_1_v3 = [1, -1]\n",
    "boundery_square_1_v4 = [-1, -1]\n",
    "# draw boundery square 1\n",
    "plt.plot([boundery_square_1_v1[0], boundery_square_1_v2[0]], [boundery_square_1_v1[1], boundery_square_1_v2[1]], color='green')\n",
    "plt.plot([boundery_square_1_v2[0], boundery_square_1_v3[0]], [boundery_square_1_v2[1], boundery_square_1_v3[1]], color='green')\n",
    "plt.plot([boundery_square_1_v3[0], boundery_square_1_v4[0]], [boundery_square_1_v3[1], boundery_square_1_v4[1]], color='green')\n",
    "plt.plot([boundery_square_1_v4[0], boundery_square_1_v1[0]], [boundery_square_1_v4[1], boundery_square_1_v1[1]], color='green')\n",
    "# vertices of boundery square 2\n",
    "boundery_square_2_v1 = [-1, 1]\n",
    "boundery_square_2_v2 = [1, 1]\n",
    "boundery_square_2_v3 = [1, 3]\n",
    "boundery_square_2_v4 = [-1, 3]\n",
    "# draw boundery square 2\n",
    "plt.plot([boundery_square_2_v1[0], boundery_square_2_v2[0]], [boundery_square_2_v1[1], boundery_square_2_v2[1]], color='green')\n",
    "plt.plot([boundery_square_2_v2[0], boundery_square_2_v3[0]], [boundery_square_2_v2[1], boundery_square_2_v3[1]], color='green')\n",
    "plt.plot([boundery_square_2_v3[0], boundery_square_2_v4[0]], [boundery_square_2_v3[1], boundery_square_2_v4[1]], color='green')\n",
    "plt.plot([boundery_square_2_v4[0], boundery_square_2_v1[0]], [boundery_square_2_v4[1], boundery_square_2_v1[1]], color='green')\n",
    "\n",
    "\n",
    "# set the limits\n",
    "plt.xlim(-3.7, 3.7)\n",
    "plt.ylim(-3.7, 3.7)\n",
    "\n",
    "# set the title\n",
    "plt.title(\"Data\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could make errors only on the buffer zone.\n",
    "\n",
    "$\\text{theorical loss} = P(x_i \\in \\text{buffer zone} )\\times(-0.7 \\times \\log(0.7) - 0.3 \\times \\log(0.3))$\n",
    "\n",
    "$P(x_i \\in \\text{buffer zone} ) = \\frac{\\text{buffer area}}{\\text{total area}} = \\frac{2 \\times (2.4^2 - 1.6^2)}{7^2} \\sim 0.13$\n",
    "\n",
    "$\\text{theorical loss} \\sim 0.13 \\times(-0.7 \\times \\log(0.7) - 0.3 \\times \\log(0.3)) \\sim 0.13 \\times 0.61 = 0.0793$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we compute the empirical loss\n",
    "empirical_loss = - np.mean(buffer_zone) * (0.3 * np.log(0.3) + 0.7 * np.log(0.7))\n",
    "\n",
    "print(f\"Empirical loss: {empirical_loss:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 2 - Questions: cross-entropy loss of a random forest**\n",
    "1. split the data into a training and a validation set and train a random forest model on the training set.\n",
    "2. On the grid of points, compute the predicted probabilities and the approximation of true cross-entropy loss.\n",
    "3. compare the cross-entropy loss of the model on the validation set to the approximation of the true cross-entropy loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. split the data into training and testing\n",
    "x_train, x_valid = x[:8000], x[8000:]\n",
    "\n",
    "# fit a random forest classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=0)\n",
    "clf.fit(x_train, classes[:8000])\n",
    "\n",
    "#2. generate the grid\n",
    "n_grid = 100\n",
    "x1x1 = np.linspace(-3.5, 3.5, n_grid)\n",
    "x2x2 = np.linspace(-3.5, 3.5, n_grid)\n",
    "X1, X2 = np.meshgrid(x1x1, x2x2)\n",
    "X = np.c_[X1.ravel(), X2.ravel()]\n",
    "\n",
    "# predict the classes\n",
    "classes_pred_probas_grid = clf.predict_proba(X)\n",
    "classes_pred_grid = clf.predict(X)\n",
    "\n",
    "# grid buffer zone\n",
    "buffer_y_inner_grid = (np.concat((np.abs(X - alpha_1).max(axis=-1)[:, None], np.abs(X - alpha_2).max(axis=-1)[:, None]), axis=-1)).min(axis=-1) - 0.8\n",
    "buffer_y_outer_grid = (np.concat((np.abs(X - alpha_1).max(axis=-1)[:, None], np.abs(X - alpha_2).max(axis=-1)[:, None]), axis=-1)).min(axis=-1) - 1.2\n",
    "buffer_inner_grid = 1 * (buffer_y_inner_grid >= 0)\n",
    "buffer_outer_grid = 1 * (buffer_y_outer_grid <= 0)\n",
    "buffer_zone_grid = buffer_inner_grid * buffer_outer_grid\n",
    "\n",
    "# grid regions\n",
    "y_true_region = (np.concat((np.abs(X - alpha_1).max(axis=-1)[:, None], np.abs(X - alpha_2).max(axis=-1)[:, None]), axis=-1)).min(axis=-1) - 1\n",
    "regions_grid = (y_true_region > 0) + 1\n",
    "\n",
    "# grid true classes probabilities\n",
    "classes_probs_grid = []\n",
    "for region, is_in_buffer_zone in zip(regions_grid.tolist(), buffer_zone_grid.tolist()):\n",
    "    if is_in_buffer_zone:\n",
    "        if region == 1:\n",
    "            classes_probs_grid.append([0.7, 0.3])\n",
    "        else:\n",
    "            classes_probs_grid.append([0.3, 0.7])\n",
    "    else:\n",
    "        classes_probs_grid.append([1, 0] if region == 1 else [0, 1])\n",
    "classes_probs_grid = np.array(classes_probs_grid)\n",
    "\n",
    "\n",
    "# compute the empirical loss\n",
    "empirical_loss = - np.sum(classes_probs_grid * np.log(classes_pred_probas_grid), axis=-1).mean()\n",
    "\n",
    "#3. predict validation set probabilities\n",
    "classes_valid_pred_probas = clf.predict_proba(x_valid)\n",
    "\n",
    "# compute validation classes probabilities\n",
    "classes_valid_probs = []\n",
    "for region, is_in_buffer_zone in zip(regions[8000:].tolist(), buffer_zone[8000:].tolist()):\n",
    "    if is_in_buffer_zone:\n",
    "        if region == 1:\n",
    "            classes_valid_probs.append([0.7, 0.3])\n",
    "        else:\n",
    "            classes_valid_probs.append([0.3, 0.7])\n",
    "    else:\n",
    "        classes_valid_probs.append([1, 0] if region == 1 else [0, 1])\n",
    "classes_valid_probs = np.array(classes_valid_probs)\n",
    "\n",
    "# compute the validation loss\n",
    "validation_loss = - np.sum(classes_valid_probs * np.log(classes_valid_pred_probas), axis=-1).mean()\n",
    "\n",
    "\n",
    "print(f\"Empirical loss: {empirical_loss:.6f}\")\n",
    "print(f\"Empirical loss on the validation set: {validation_loss:.6f}\")\n",
    "\n",
    "\n",
    "# plot the data with small sizes for scattered points\n",
    "plt.scatter(X[classes_pred_grid == 0, 0], X[classes_pred_grid == 0, 1], color='purple', label='Class 0', s=1)\n",
    "plt.scatter(X[classes_pred_grid == 1, 0], X[classes_pred_grid == 1, 1], color='orange', label='Class 1', s=1)\n",
    "plt.legend()\n",
    "plt.xlabel(\"x1\")\n",
    "plt.ylabel(\"x2\")\n",
    "plt.title(\"Predicted classes on the grid using random forest\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
